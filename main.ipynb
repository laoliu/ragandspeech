{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 环境安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 创建一个虚拟环境，最好放到外面的terminal下执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda create --name hwfinal python=3.11.8\n",
    "# %conda activate hwfinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 VScode右上角的当前kernel，选择前面新建的kernel hwfinal，并安装以下必要的包，运行前会提示安装ipjupyter，选择是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper==20231117\n",
      "  Using cached openai_whisper-20231117-py3-none-any.whl\n",
      "Collecting triton<3,>=2.0.0 (from openai-whisper==20231117)\n",
      "  Using cached triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting numba (from openai-whisper==20231117)\n",
      "  Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from openai-whisper==20231117) (1.26.4)\n",
      "Collecting torch (from openai-whisper==20231117)\n",
      "  Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tqdm in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from openai-whisper==20231117) (4.66.5)\n",
      "Collecting more-itertools (from openai-whisper==20231117)\n",
      "  Using cached more_itertools-10.4.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting tiktoken (from openai-whisper==20231117)\n",
      "  Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper==20231117)\n",
      "  Using cached llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper==20231117)\n",
      "  Using cached regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
      "Collecting sympy (from torch->openai-whisper==20231117)\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->openai-whisper==20231117)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch (from openai-whisper==20231117)\n",
      "  Using cached torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch->openai-whisper==20231117)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "Using cached more_itertools-10.4.0-py3-none-any.whl (60 kB)\n",
      "Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Using cached regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (786 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: mpmath, triton, sympy, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, more-itertools, llvmlite, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nvidia-cusolver-cu12, torch, openai-whisper\n",
      "Successfully installed llvmlite-0.43.0 more-itertools-10.4.0 mpmath-1.3.0 networkx-3.3 numba-0.60.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 regex-2024.7.24 sympy-1.13.2 tiktoken-0.7.0 torch-2.3.1 triton-2.3.1\n",
      "Collecting ffmpeg==1.4\n",
      "  Using cached ffmpeg-1.4-py3-none-any.whl\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/liu/miniconda3/envs/hwfinal\n",
      "\n",
      "  added / updated specs:\n",
      "    - ffmpeg\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aom                pkgs/main/linux-64::aom-3.6.0-h6a678d5_0 \n",
      "  cairo              pkgs/main/linux-64::cairo-1.16.0-hb05425b_5 \n",
      "  dav1d              pkgs/main/linux-64::dav1d-1.2.1-h5eee18b_0 \n",
      "  expat              pkgs/main/linux-64::expat-2.6.2-h6a678d5_0 \n",
      "  ffmpeg             pkgs/main/linux-64::ffmpeg-6.1.1-h4c62175_0 \n",
      "  fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h4c34cd2_2 \n",
      "  freetype           pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0 \n",
      "  giflib             pkgs/main/linux-64::giflib-5.2.1-h5eee18b_3 \n",
      "  glib               pkgs/main/linux-64::glib-2.78.4-h6a678d5_0 \n",
      "  glib-tools         pkgs/main/linux-64::glib-tools-2.78.4-h6a678d5_0 \n",
      "  graphite2          pkgs/main/linux-64::graphite2-1.3.14-h295c915_1 \n",
      "  harfbuzz           pkgs/main/linux-64::harfbuzz-4.3.0-hf52aaf7_2 \n",
      "  icu                pkgs/main/linux-64::icu-73.1-h6a678d5_0 \n",
      "  jpeg               pkgs/main/linux-64::jpeg-9e-h5eee18b_3 \n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 \n",
      "  leptonica          pkgs/main/linux-64::leptonica-1.82.0-h42c8aad_2 \n",
      "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 \n",
      "  libarchive         pkgs/main/linux-64::libarchive-3.6.2-h6ac8c49_3 \n",
      "  libdeflate         pkgs/main/linux-64::libdeflate-1.17-h5eee18b_1 \n",
      "  libglib            pkgs/main/linux-64::libglib-2.78.4-hdc74915_0 \n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 \n",
      "  libogg             pkgs/main/linux-64::libogg-1.3.5-h27cfd23_1 \n",
      "  libopus            pkgs/main/linux-64::libopus-1.3.1-h7b6447c_0 \n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 \n",
      "  libtheora          pkgs/main/linux-64::libtheora-1.1.1-h7f8727e_3 \n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.5.1-h6a678d5_0 \n",
      "  libvorbis          pkgs/main/linux-64::libvorbis-1.3.7-h7b6447c_0 \n",
      "  libvpx             pkgs/main/linux-64::libvpx-1.13.1-h6a678d5_0 \n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.3.2-h11a3e52_0 \n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.3.2-h5eee18b_0 \n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.15-h7f8727e_0 \n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.10.4-hfdd30dd_2 \n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1 \n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 \n",
      "  openjpeg           pkgs/main/linux-64::openjpeg-2.5.2-he7f1fd0_0 \n",
      "  pcre2              pkgs/main/linux-64::pcre2-10.42-hebb0a14_1 \n",
      "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7f8727e_1 \n",
      "  tesseract          pkgs/main/linux-64::tesseract-5.2.0-h6a678d5_0 \n",
      "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting edge-tts\n",
      "  Using cached edge_tts-6.1.12-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: aiohttp>=3.8.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from edge-tts) (3.10.3)\n",
      "Requirement already satisfied: certifi>=2023.11.17 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from edge-tts) (2024.7.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from aiohttp>=3.8.0->edge-tts) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from aiohttp>=3.8.0->edge-tts) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from aiohttp>=3.8.0->edge-tts) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from aiohttp>=3.8.0->edge-tts) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from aiohttp>=3.8.0->edge-tts) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from aiohttp>=3.8.0->edge-tts) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.0->edge-tts) (3.7)\n",
      "Using cached edge_tts-6.1.12-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: edge-tts\n",
      "Successfully installed edge-tts-6.1.12\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Using cached transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "Using cached safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ! pip install langchain-nvidia-ai-endpoints\n",
    "# ! pip install jupyterlab\n",
    "# ! pip install langchain_core\n",
    "# ! pip install langchain\n",
    "# ! pip install langchain-community\n",
    "# ! pip install matplotlib\n",
    "# ! pip install numpy\n",
    "# ! pip install openai\n",
    "# ! pip install gradio\n",
    "# ! pip install faiss-cpu\n",
    "\n",
    "# ! pip install openai-whisper==20231117 \n",
    "# ! pip install ffmpeg==1.4\n",
    "# ! conda install ffmpeg -y\n",
    "# ! pip install edge-tts\n",
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 设置 NVIDIA APIKEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = os.environ[\"NVIDIA_API_KEY\"]\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 建立知识库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 选择推理模型及对应的嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_statics.py:579: UserWarning: Model ai-phi-3-small-128k-instruct is deprecated. Using microsoft/phi-3-small-128k-instruct instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "llm = ChatNVIDIA(model=\"ai-phi-3-small-128k-instruct\", nvidia_api_key=nvapi_key, max_tokens=512)\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"NV-Embed-QA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 构建文档数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Here we read in the text data and prepare them into vectorstore\n",
    "ps = os.listdir(\"./zh_data/\")\n",
    "data = []\n",
    "sources = []\n",
    "for p in ps:\n",
    "    if p.endswith('.txt'):\n",
    "        path2file=\"./zh_data/\"+p\n",
    "        with open(path2file,encoding=\"utf-8\") as f:\n",
    "            lines=f.readlines()\n",
    "            for line in lines:\n",
    "                if len(line)>=1:\n",
    "                    data.append(line)\n",
    "                    sources.append(path2file)\n",
    "                    \n",
    "documents=[d for d in data if d != '\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 保存到向量库(流程一)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=400, separator=\" \")\n",
    "docs = []\n",
    "metadatas = []\n",
    "\n",
    "for i, d in enumerate(documents):\n",
    "    splits = text_splitter.split_text(d)\n",
    "    #print(len(splits))\n",
    "    docs.extend(splits)\n",
    "    metadatas.extend([{\"source\": sources[i]}] * len(splits))\n",
    "\n",
    "store = FAISS.from_texts(docs, embedder , metadatas=metadatas)\n",
    "store.save_local('./zh_data/nv_embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2 从向量库中取出内容(流程二)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FAISS.load_local(\"./zh_data/nv_embedding\", embedder,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 主流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 phi模型根据提示进行回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_demo(mesage):\n",
    "    retriever = store.as_retriever()\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
    "            ),\n",
    "            (\"user\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = chain.invoke(mesage)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 定义辅助函数1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Edge TTS\n",
    "def calculate_rate_string(input_value):\n",
    "    rate = (input_value - 1) * 100\n",
    "    sign = '+' if input_value >= 1 else '-'\n",
    "    return f\"{sign}{abs(int(rate))}\"\n",
    "\n",
    "\n",
    "def make_chunks(input_text, language):\n",
    "    language=\"English\"\n",
    "    if language == \"English\":\n",
    "      temp_list = input_text.strip().split(\".\")\n",
    "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
    "      if temp_list[-1].strip():\n",
    "          filtered_list.append(temp_list[-1].strip())\n",
    "      return filtered_list\n",
    "\n",
    "\n",
    "import uuid\n",
    "def tts_file_name(text):\n",
    "    if text.endswith(\".\"):\n",
    "        text = text[:-1]\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace(\" \",\"_\")\n",
    "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
    "    random_string = uuid.uuid4().hex[:8].upper()\n",
    "    file_name = f\"./content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
    "    return file_name\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import os\n",
    "def merge_audio_files(audio_paths, output_path):\n",
    "    # Initialize an empty AudioSegment\n",
    "    merged_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through each audio file path\n",
    "    for audio_path in audio_paths:\n",
    "        # Load the audio file using Pydub\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "        # Append the current audio file to the merged_audio\n",
    "        merged_audio += audio\n",
    "\n",
    "    # Export the merged audio to the specified output path\n",
    "    merged_audio.export(output_path, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 定义辅助函数2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
    "  # print(chunks_list)\n",
    "  if len(chunks_list)>1:\n",
    "    chunk_audio_list=[]\n",
    "    if os.path.exists(\"./content/edge_tts_voice\"):\n",
    "      shutil.rmtree(\"./content/edge_tts_voice\")\n",
    "    os.mkdir(\"./content/edge_tts_voice\")\n",
    "    k=1\n",
    "    for i in chunks_list:\n",
    "      print(i)\n",
    "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media ./content/edge_tts_voice/{k}.mp3'\n",
    "      print(edge_command)\n",
    "      var1=os.system(edge_command)\n",
    "      if var1==0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f\"Failed: {i}\")\n",
    "      chunk_audio_list.append(f\"./content/edge_tts_voice/{k}.mp3\")\n",
    "      k+=1\n",
    "    # print(chunk_audio_list)\n",
    "    merge_audio_files(chunk_audio_list, save_path)\n",
    "  else:\n",
    "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
    "    print(edge_command)\n",
    "    var2=os.system(edge_command)\n",
    "    if var2==0:\n",
    "      pass\n",
    "    else:\n",
    "      print(f\"Failed: {chunks_list[0]}\")\n",
    "  return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 定义辅助函数3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(\"./content/audio\"):\n",
    "    os.mkdir(\"./content/audio\")\n",
    "import uuid\n",
    "def random_audio_name_generate():\n",
    "  random_uuid = uuid.uuid4()\n",
    "  audio_extension = \".mp3\"\n",
    "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
    "  return random_audio_name\n",
    "\n",
    "text = 'This is Microsoft Phi 3 mini 4k instruct Demo'  # @param {type: \"string\"}\n",
    "Language = \"English\" # @param ['English']\n",
    "# Gender of voice simply change from male to female and choose the voice you want to use\n",
    "Gender = \"Female\"# @param ['Male', 'Female']\n",
    "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
    "speed = 1  # @param {type: \"number\"}\n",
    "translate_text_flag  = False\n",
    "if len(text)>=600:\n",
    "  long_sentence = True\n",
    "else:\n",
    "  long_sentence = False\n",
    "\n",
    "# long_sentence = False # @param {type:\"boolean\"}\n",
    "save_path = ''  # @param {type: \"string\"}\n",
    "if len(save_path)==0:\n",
    "  save_path=tts_file_name(text)\n",
    "if Language == \"English\" :\n",
    "  if Gender==\"Male\":\n",
    "    voice_name=\"en-US-ChristopherNeural\"\n",
    "  if Gender==\"Female\":\n",
    "    voice_name=female_voice\n",
    "\n",
    "def talk(input_text):\n",
    "  global translate_text_flag,Language,speed,voice_name\n",
    "  if len(input_text)>=600:\n",
    "    long_sentence = True\n",
    "  else:\n",
    "    long_sentence = False\n",
    "\n",
    "  if long_sentence==True and translate_text_flag==True:\n",
    "    chunks_list=make_chunks(input_text,Language)\n",
    "  elif long_sentence==True and translate_text_flag==False:\n",
    "    chunks_list=make_chunks(input_text,\"English\")\n",
    "  else:\n",
    "    chunks_list=[input_text]\n",
    "  save_path=\"./content/audio/\"+random_audio_name_generate()\n",
    "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
    "  return edge_save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 定义辅助函数4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "select_model =\"tiny\" # ['tiny', 'base']\n",
    "whisper_model = whisper.load_model(select_model)\n",
    "\n",
    "def convert_to_text(audio_path):\n",
    "  result = whisper_model.transcribe(audio_path,word_timestamps=True,fp16=False,language='English',task='translate')\n",
    "  with open('scan.txt', 'w') as file:\n",
    "    file.write(str(result))\n",
    "  return result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 定义主流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liu/miniconda3/envs/hwfinal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://66c8760b27ce8ed3f8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://66c8760b27ce8ed3f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Run gradio app\n",
    "import gradio as gr\n",
    "from IPython.display import Audio, display\n",
    "def run_text_prompt(message, chat_history):\n",
    "    bot_message = phi_demo(message)\n",
    "    edge_save_path=talk(bot_message)\n",
    "    # print(edge_save_path)\n",
    "    display(Audio(edge_save_path, autoplay=True))\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "\n",
    "def run_audio_prompt(audio, chat_history):\n",
    "    if audio is None:\n",
    "        return None, chat_history\n",
    "    print(audio)\n",
    "    message_transcription = convert_to_text(audio)\n",
    "    _, chat_history = run_text_prompt(message_transcription, chat_history)\n",
    "    return None, chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Phi 3 mini 4k instruct\")\n",
    "\n",
    "    msg = gr.Textbox(label=\"Ask anything\")\n",
    "    msg.submit(run_text_prompt, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    with gr.Row():\n",
    "        audio = gr.Audio(sources=\"microphone\", type=\"filepath\")\n",
    "\n",
    "        send_audio_button = gr.Button(\"Send Audio\", interactive=True)\n",
    "        send_audio_button.click(run_audio_prompt, [audio, chatbot], [audio, chatbot])\n",
    "\n",
    "demo.launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_endpoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
